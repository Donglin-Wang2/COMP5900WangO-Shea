{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit ('comp5900porj')",
   "metadata": {
    "interpreter": {
     "hash": "8608f3369e1b7fe199f3056150d4f7c6c375e24eac93172fa646af6324355164"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(50000, 1280) (10000, 1280)\n",
      "(50000, 2048) (10000, 2048)\n"
     ]
    }
   ],
   "source": [
    "model_name = 'mobilenet'\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar100.load_data()\n",
    "imagenet_feat_train = np.load('./data/CIFAR100_%s_train_feat.npy' % model_name)\n",
    "imagenet_feat_test = np.load('./data/CIFAR100_%s_test_feat.npy' % model_name)[-10000:]\n",
    "print(imagenet_feat_train.shape, imagenet_feat_test.shape)\n",
    "vae_vanilla_encoding_train = np.load('./data/CIFAR100_vae_vanilla_inception_encoding_train.npy')\n",
    "vae_vanilla_encoding_test = np.load('./data/CIFAR100_vae_vanilla_inception_encoding_test.npy')[-10000:]\n",
    "vae_adapted_encoding_train = np.load('./data/CIFAR100_vae_adapted_inception_encoding_train.npy')\n",
    "vae_injected_encoding_train = np.load('./data/CIFAR100_vae_injected_inception_encoding_train.npy')\n",
    "print(vae_vanilla_encoding_train.shape, vae_vanilla_encoding_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 512)               655872    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 832,996\n",
      "Trainable params: 832,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 4.4759 - accuracy: 0.0413\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 4.1726 - accuracy: 0.0771\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 4.0797 - accuracy: 0.0915\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 4.0348 - accuracy: 0.0986\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.9998 - accuracy: 0.1010\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.9771 - accuracy: 0.1068\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.9554 - accuracy: 0.1105\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.9446 - accuracy: 0.1114\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.9244 - accuracy: 0.1144\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.9204 - accuracy: 0.1132\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.9014 - accuracy: 0.1183\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.9058 - accuracy: 0.1183\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.8888 - accuracy: 0.1200\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.8903 - accuracy: 0.1223\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.8805 - accuracy: 0.1241\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.8631 - accuracy: 0.1233\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.8608 - accuracy: 0.1269\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.8572 - accuracy: 0.1265\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.8514 - accuracy: 0.1268\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.8440 - accuracy: 0.1274\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.8464 - accuracy: 0.1266\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.8476 - accuracy: 0.1254\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.8395 - accuracy: 0.1261\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.8307 - accuracy: 0.1283\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.8272 - accuracy: 0.1302\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.8259 - accuracy: 0.1309\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.8137 - accuracy: 0.1303\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.8245 - accuracy: 0.1298\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.8144 - accuracy: 0.1310\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.8096 - accuracy: 0.1323\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.8099 - accuracy: 0.1306\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7943 - accuracy: 0.1324\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7864 - accuracy: 0.1371\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7941 - accuracy: 0.1339\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.8013 - accuracy: 0.1310\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7900 - accuracy: 0.1335\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7926 - accuracy: 0.1341\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 3.7987 - accuracy: 0.1320\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7931 - accuracy: 0.1328\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7828 - accuracy: 0.1350\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7736 - accuracy: 0.1347\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7792 - accuracy: 0.1364\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7708 - accuracy: 0.1378\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7795 - accuracy: 0.1333\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7756 - accuracy: 0.1366\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7798 - accuracy: 0.1362\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7616 - accuracy: 0.1401\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7676 - accuracy: 0.1379\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7673 - accuracy: 0.1355\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7556 - accuracy: 0.1387\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7563 - accuracy: 0.1378\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7579 - accuracy: 0.1389\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7552 - accuracy: 0.1399\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7602 - accuracy: 0.1370\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7652 - accuracy: 0.1372\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7527 - accuracy: 0.1391\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7497 - accuracy: 0.1400\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7586 - accuracy: 0.1395\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7486 - accuracy: 0.1405\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7506 - accuracy: 0.1402\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7494 - accuracy: 0.1390\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7346 - accuracy: 0.1420\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7416 - accuracy: 0.1424\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7326 - accuracy: 0.1404\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7364 - accuracy: 0.1435\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7459 - accuracy: 0.1379\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7401 - accuracy: 0.1396\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.7430 - accuracy: 0.1408\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7393 - accuracy: 0.1414\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7395 - accuracy: 0.1402\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7332 - accuracy: 0.1400\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7249 - accuracy: 0.1440\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7345 - accuracy: 0.1421\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7336 - accuracy: 0.1436\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.7270 - accuracy: 0.1419\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7288 - accuracy: 0.1420\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.7321 - accuracy: 0.1429\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.7199 - accuracy: 0.1431\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7297 - accuracy: 0.1432\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7228 - accuracy: 0.1418\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7295 - accuracy: 0.1416\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7295 - accuracy: 0.1405\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7249 - accuracy: 0.1430\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7248 - accuracy: 0.1455\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7190 - accuracy: 0.1429\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7262 - accuracy: 0.1413\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7178 - accuracy: 0.1424\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7086 - accuracy: 0.1434\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.7184 - accuracy: 0.1448\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7312 - accuracy: 0.1400\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7182 - accuracy: 0.1449\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7198 - accuracy: 0.1418\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.7090 - accuracy: 0.1474\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.7257 - accuracy: 0.1428\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7113 - accuracy: 0.1439\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7292 - accuracy: 0.1386\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7079 - accuracy: 0.1436\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 3.7148 - accuracy: 0.1433\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 3.7202 - accuracy: 0.1429\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 3.7122 - accuracy: 0.1427\n"
     ]
    }
   ],
   "source": [
    "imagenet_model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(1280,)),\n",
    "    Dense(512),\n",
    "    Dense(256),\n",
    "    Dense(128),\n",
    "    Dense(100, activation='sigmoid')\n",
    "])\n",
    "imagenet_model.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "imagenet_model.summary()\n",
    "imagenet_history = imagenet_model.fit(x=imagenet_feat_train, y=train_labels, epochs=100)\n",
    "np.save('./mobilenet_classifier_history', imagenet_history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 1,226,212\n",
      "Trainable params: 1,226,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 6.4105 - accuracy: 0.0144\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 4.2119 - accuracy: 0.0808\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 3.7461 - accuracy: 0.1454\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 3.4747 - accuracy: 0.1961\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 3.2636 - accuracy: 0.2391\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 3.0987 - accuracy: 0.2717\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.9645 - accuracy: 0.2982\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.8292 - accuracy: 0.3281\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.7406 - accuracy: 0.3440\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.6551 - accuracy: 0.3631\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.5929 - accuracy: 0.3792\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.5161 - accuracy: 0.3933\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.4777 - accuracy: 0.4016\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.4286 - accuracy: 0.4197\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.3955 - accuracy: 0.4215\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.3555 - accuracy: 0.4283\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.3288 - accuracy: 0.4344\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.3088 - accuracy: 0.4382\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.2883 - accuracy: 0.4438\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.2748 - accuracy: 0.4436\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.2580 - accuracy: 0.4492\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.2435 - accuracy: 0.4574\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.2482 - accuracy: 0.4523\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.2328 - accuracy: 0.4554\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.2151 - accuracy: 0.4643\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.2036 - accuracy: 0.4636\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.2022 - accuracy: 0.4628\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1940 - accuracy: 0.4674\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1954 - accuracy: 0.4647\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.2017 - accuracy: 0.4630\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.1759 - accuracy: 0.4703\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1741 - accuracy: 0.4691\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1789 - accuracy: 0.4700\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1636 - accuracy: 0.4701\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.1578 - accuracy: 0.4712\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.1621 - accuracy: 0.4711\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1386 - accuracy: 0.4778\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.1496 - accuracy: 0.4792\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.1364 - accuracy: 0.4771\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.1351 - accuracy: 0.4754\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1414 - accuracy: 0.4792\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.1250 - accuracy: 0.4809\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1329 - accuracy: 0.4807\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.1187 - accuracy: 0.4802\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.1231 - accuracy: 0.4766\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1198 - accuracy: 0.4783\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1202 - accuracy: 0.4855\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1112 - accuracy: 0.4840\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.1200 - accuracy: 0.4808\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.1111 - accuracy: 0.4828\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0982 - accuracy: 0.4860\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.1040 - accuracy: 0.4836\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0971 - accuracy: 0.4848\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.1067 - accuracy: 0.4810\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0966 - accuracy: 0.4838\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.0948 - accuracy: 0.4860\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.0977 - accuracy: 0.4881\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1109 - accuracy: 0.4814\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.1006 - accuracy: 0.4840\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0868 - accuracy: 0.4875\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0915 - accuracy: 0.4864\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0812 - accuracy: 0.4902\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.0954 - accuracy: 0.4842\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.0839 - accuracy: 0.4865\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0895 - accuracy: 0.4855\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0830 - accuracy: 0.4863\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0763 - accuracy: 0.4900\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0860 - accuracy: 0.4865\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0708 - accuracy: 0.4878\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0653 - accuracy: 0.4919\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0537 - accuracy: 0.4950\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0714 - accuracy: 0.4939\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.0640 - accuracy: 0.4906\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.0633 - accuracy: 0.4918\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0754 - accuracy: 0.4908\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0699 - accuracy: 0.4905\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.0554 - accuracy: 0.4913\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0692 - accuracy: 0.4900\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0572 - accuracy: 0.4957\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0467 - accuracy: 0.4965\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0513 - accuracy: 0.4937\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0635 - accuracy: 0.4897\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0628 - accuracy: 0.4949\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.0437 - accuracy: 0.4939\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.0505 - accuracy: 0.4976\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0461 - accuracy: 0.4935\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0546 - accuracy: 0.4945\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0567 - accuracy: 0.4915\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.0551 - accuracy: 0.4962\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0475 - accuracy: 0.4929\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0540 - accuracy: 0.4920\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.0561 - accuracy: 0.4933\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0373 - accuracy: 0.4983\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.0474 - accuracy: 0.4951\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0542 - accuracy: 0.4948\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0486 - accuracy: 0.4916\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0319 - accuracy: 0.4995\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0294 - accuracy: 0.5016\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.0129 - accuracy: 0.5030\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0372 - accuracy: 0.4939\n"
     ]
    }
   ],
   "source": [
    "vae_vanilla_classifier = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(2048,)),\n",
    "    Dense(512),\n",
    "    Dense(256),\n",
    "    Dense(128),\n",
    "    Dense(100, activation='sigmoid')\n",
    "])\n",
    "vae_vanilla_classifier.summary()\n",
    "vae_vanilla_classifier.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "vae_vanilla_history = vae_vanilla_classifier.fit(x=vae_vanilla_encoding_train, y=train_labels, epochs=100)\n",
    "np.save('./vae_vanilla_inception_classifier_history', vae_vanilla_history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 1,226,212\n",
      "Trainable params: 1,226,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 6.2367 - accuracy: 0.0517\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 3.3226 - accuracy: 0.2356\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.7761 - accuracy: 0.3337\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.4730 - accuracy: 0.3954\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.2531 - accuracy: 0.4460\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0725 - accuracy: 0.4882\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.9312 - accuracy: 0.5198\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7967 - accuracy: 0.5531\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.6855 - accuracy: 0.5795\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.6023 - accuracy: 0.5960\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4909 - accuracy: 0.6279\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4246 - accuracy: 0.6435\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3668 - accuracy: 0.6559\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3028 - accuracy: 0.6741\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2473 - accuracy: 0.6879\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1876 - accuracy: 0.7019\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1409 - accuracy: 0.7109\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0983 - accuracy: 0.7232\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.0664 - accuracy: 0.7282\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0158 - accuracy: 0.7430\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9840 - accuracy: 0.7513\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9717 - accuracy: 0.7525\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9393 - accuracy: 0.7597\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9002 - accuracy: 0.7666\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.8868 - accuracy: 0.7712\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.8709 - accuracy: 0.7718\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8410 - accuracy: 0.7810\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8127 - accuracy: 0.7874\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.8064 - accuracy: 0.7853\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7795 - accuracy: 0.7945\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7645 - accuracy: 0.8001\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.7646 - accuracy: 0.7936\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.7268 - accuracy: 0.8051\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7166 - accuracy: 0.8077\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7044 - accuracy: 0.8096\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6851 - accuracy: 0.8144\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6747 - accuracy: 0.8163\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6623 - accuracy: 0.8195\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.6458 - accuracy: 0.8202\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6457 - accuracy: 0.8217\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6276 - accuracy: 0.8291\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.6237 - accuracy: 0.8245\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.6019 - accuracy: 0.8307\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.5914 - accuracy: 0.8342\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.5814 - accuracy: 0.8374\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5708 - accuracy: 0.8348\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5691 - accuracy: 0.8386\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5645 - accuracy: 0.8371\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5499 - accuracy: 0.8392\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5377 - accuracy: 0.8432\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5350 - accuracy: 0.8441\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.5179 - accuracy: 0.8492\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.5200 - accuracy: 0.8467\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5125 - accuracy: 0.8520\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4911 - accuracy: 0.8550\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4934 - accuracy: 0.8515\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4866 - accuracy: 0.8558\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4836 - accuracy: 0.8569\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4796 - accuracy: 0.8555\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4652 - accuracy: 0.8583\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4572 - accuracy: 0.8620\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4649 - accuracy: 0.8585\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4536 - accuracy: 0.8605\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4496 - accuracy: 0.8611\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4331 - accuracy: 0.8648\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4267 - accuracy: 0.8667\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4381 - accuracy: 0.8618\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4228 - accuracy: 0.8698\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.4245 - accuracy: 0.8680\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.4138 - accuracy: 0.8676\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4062 - accuracy: 0.8718\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.4089 - accuracy: 0.8709\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3977 - accuracy: 0.8752\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3964 - accuracy: 0.8733\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3869 - accuracy: 0.8761\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3986 - accuracy: 0.8726\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3851 - accuracy: 0.8774\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3860 - accuracy: 0.8778\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3764 - accuracy: 0.8797\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.3672 - accuracy: 0.8801\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3717 - accuracy: 0.8797\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3676 - accuracy: 0.8815\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3679 - accuracy: 0.8816\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3644 - accuracy: 0.8816\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.3636 - accuracy: 0.8809\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3580 - accuracy: 0.8853\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3541 - accuracy: 0.8834\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3574 - accuracy: 0.8803\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.3490 - accuracy: 0.8867\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3442 - accuracy: 0.8869\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3382 - accuracy: 0.8885\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3433 - accuracy: 0.8844\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3270 - accuracy: 0.8912\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3390 - accuracy: 0.8866\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3217 - accuracy: 0.8915\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3337 - accuracy: 0.8891\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.3283 - accuracy: 0.8925\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3212 - accuracy: 0.8918\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3087 - accuracy: 0.8977\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3356 - accuracy: 0.8867\n"
     ]
    }
   ],
   "source": [
    "vae_adapted_classifier = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(2048,)),\n",
    "    Dense(512),\n",
    "    Dense(256),\n",
    "    Dense(128),\n",
    "    Dense(100, activation='sigmoid')\n",
    "])\n",
    "vae_adapted_classifier.summary()\n",
    "vae_adapted_classifier.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "vae_adapted_history = vae_adapted_classifier.fit(x=vae_adapted_encoding_train, y=train_labels, epochs=100)\n",
    "np.save('./vae_adapted_inception_classifier_history', vae_adapted_history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               12900     \n",
      "=================================================================\n",
      "Total params: 1,226,212\n",
      "Trainable params: 1,226,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 6.3604 - accuracy: 0.0278\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 3.7905 - accuracy: 0.1567\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 3.2653 - accuracy: 0.2420\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.9407 - accuracy: 0.3047\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.7130 - accuracy: 0.3501\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.5235 - accuracy: 0.3919\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.3859 - accuracy: 0.4226\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.2562 - accuracy: 0.4516\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.1379 - accuracy: 0.4813\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0541 - accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.9797 - accuracy: 0.5146\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8912 - accuracy: 0.5341\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.8259 - accuracy: 0.5531\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7809 - accuracy: 0.5623\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7343 - accuracy: 0.5711\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7011 - accuracy: 0.5805\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6527 - accuracy: 0.5907\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6317 - accuracy: 0.6035\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5985 - accuracy: 0.6054\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5855 - accuracy: 0.6079\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5507 - accuracy: 0.6173\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5192 - accuracy: 0.6209\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5004 - accuracy: 0.6268\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4887 - accuracy: 0.6302\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4801 - accuracy: 0.6307\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4586 - accuracy: 0.6391\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4471 - accuracy: 0.6418\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4220 - accuracy: 0.6434\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.4161 - accuracy: 0.6444\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4069 - accuracy: 0.6523\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3805 - accuracy: 0.6537\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3805 - accuracy: 0.6515\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3610 - accuracy: 0.6582\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3702 - accuracy: 0.6557\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3533 - accuracy: 0.6568\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3374 - accuracy: 0.6626\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3330 - accuracy: 0.6662\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3329 - accuracy: 0.6637\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3159 - accuracy: 0.6663\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2999 - accuracy: 0.6689\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2935 - accuracy: 0.6732\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.2924 - accuracy: 0.6706\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2779 - accuracy: 0.6737\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2834 - accuracy: 0.6713\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2879 - accuracy: 0.6744\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2752 - accuracy: 0.6726\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2564 - accuracy: 0.6785\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2536 - accuracy: 0.6781\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2598 - accuracy: 0.6771\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2373 - accuracy: 0.6835\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2291 - accuracy: 0.6822\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2320 - accuracy: 0.6827\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2168 - accuracy: 0.6875\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2168 - accuracy: 0.6851\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2151 - accuracy: 0.6871\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2118 - accuracy: 0.6882\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2055 - accuracy: 0.6896\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2017 - accuracy: 0.6917\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1983 - accuracy: 0.6891\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1910 - accuracy: 0.6911\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1827 - accuracy: 0.6940\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1859 - accuracy: 0.6937\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1820 - accuracy: 0.6904\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1680 - accuracy: 0.6997\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1668 - accuracy: 0.6971\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1653 - accuracy: 0.6965\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1674 - accuracy: 0.6945\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1434 - accuracy: 0.7057\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1457 - accuracy: 0.7018\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1486 - accuracy: 0.6961\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1507 - accuracy: 0.6979\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1467 - accuracy: 0.6981\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1438 - accuracy: 0.7025\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1366 - accuracy: 0.6997\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1448 - accuracy: 0.6999\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1334 - accuracy: 0.7047\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1247 - accuracy: 0.7064\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1141 - accuracy: 0.7080\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1153 - accuracy: 0.7074\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1107 - accuracy: 0.7119\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1092 - accuracy: 0.7070\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.0958 - accuracy: 0.7090\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1071 - accuracy: 0.7083\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.0928 - accuracy: 0.7118\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.0921 - accuracy: 0.7139\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0942 - accuracy: 0.7114\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0860 - accuracy: 0.7111\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0908 - accuracy: 0.7111\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0776 - accuracy: 0.7155\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0778 - accuracy: 0.7129\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0711 - accuracy: 0.7182\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0818 - accuracy: 0.7136\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0637 - accuracy: 0.7150\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0729 - accuracy: 0.7178\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0714 - accuracy: 0.7165\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0692 - accuracy: 0.7142\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0562 - accuracy: 0.7213\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0598 - accuracy: 0.7182\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0562 - accuracy: 0.7196\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0607 - accuracy: 0.7153\n"
     ]
    }
   ],
   "source": [
    "vae_injected_classifier = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(2048,)),\n",
    "    Dense(512),\n",
    "    Dense(256),\n",
    "    Dense(128),\n",
    "    Dense(100, activation='sigmoid')\n",
    "])\n",
    "vae_injected_classifier.summary()\n",
    "vae_injected_classifier.compile(optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "vae_injected_history = vae_injected_classifier.fit(x=vae_injected_encoding_train, y=train_labels, epochs=100)\n",
    "np.save('./vae_injected_inception_classifier_history', vae_injected_history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_10 (Conv2D)           (None, 128, 128, 8)       224       \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 64, 64, 16)        1168      \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 32, 32, 32)        4640      \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 16, 16, 64)        18496     \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 8, 8, 128)         73856     \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 8192)              0         \n=================================================================\nTotal params: 98,384\nTrainable params: 98,384\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_15 (Conv2D)           (None, 128, 128, 8)       224       \n_________________________________________________________________\nconv2d_16 (Conv2D)           (None, 64, 64, 16)        1168      \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, 32, 32, 32)        4640      \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, 16, 16, 64)        18496     \n_________________________________________________________________\nconv2d_19 (Conv2D)           (None, 8, 8, 128)         73856     \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 8192)              0         \n=================================================================\nTotal params: 98,384\nTrainable params: 98,384\nNon-trainable params: 0\n_________________________________________________________________\nModel: \"sequential_8\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_17 (Dense)             (None, 8192)              4202496   \n_________________________________________________________________\nreshape_1 (Reshape)          (None, 8, 8, 128)         0         \n_________________________________________________________________\nconv2d_transpose_5 (Conv2DTr (None, 16, 16, 128)       147584    \n_________________________________________________________________\nconv2d_transpose_6 (Conv2DTr (None, 32, 32, 64)        73792     \n_________________________________________________________________\nconv2d_transpose_7 (Conv2DTr (None, 64, 64, 32)        18464     \n_________________________________________________________________\nconv2d_transpose_8 (Conv2DTr (None, 128, 128, 16)      4624      \n_________________________________________________________________\nconv2d_transpose_9 (Conv2DTr (None, 256, 256, 1)       145       \n=================================================================\nTotal params: 4,447,105\nTrainable params: 4,447,105\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Dense' object has no attribute 'summary'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5b19751f52d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_log_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dense' object has no attribute 'summary'"
     ]
    }
   ],
   "source": [
    "from vae_vanilla import VAE\n",
    "model = VAE(512)\n",
    "model.img_encoder.summary()\n",
    "model.depth_encoder.summary()\n",
    "model.decoder.summary()\n",
    "model.fc_log_var.summary()\n",
    "model.fc_mean.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}