{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from vae_adapted import VAEAdapted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9 5\n"
     ]
    }
   ],
   "source": [
    "## Loading dataset\n",
    "model_name = \"inception\"\n",
    "assert model_name in ['inception', 'vgg', 'resnet', 'mobilenet']\n",
    "labels = np.load('./data/LFSD_labels.npy')\n",
    "depths = np.load('./data/LFSD_depths_repeated_%s_feat.npy' % model_name)\n",
    "imgs = np.load('./data/LFSD_imgs_%s_feat.npy' % model_name)\n",
    "masks = np.load('./data/LFSD_masks_single.npy')\n",
    "\n",
    "def built_batch_iterator(num_data, batch_size):\n",
    "    idx = np.random.permutation(num_data)\n",
    "    return [idx[i:i + batch_size] for i in range(0, num_data, batch_size)]\n",
    "\n",
    "batch_idxs = built_batch_iterator(len(labels), 64)\n",
    "dataset = []\n",
    "for idx in batch_idxs:\n",
    "    img_batch, depth_batch, mask_batch = imgs[idx], depths[idx], masks[idx]\n",
    "    dataset.append((img_batch, depth_batch, mask_batch))\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.3)\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0: \n",
      "Total loss: 3005601\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "vae = VAEAdapted(latent_dim)\n",
    "learning_rate = 1e-4\n",
    "vae.compile(optimizer=Adam(learning_rate))\n",
    "epochs = 1\n",
    "\n",
    "def merge_images(image_batch, size):\n",
    "    h,w = image_batch.shape[1], image_batch.shape[2]\n",
    "    img = np.zeros((int(h*size[0]), w*size[1]))\n",
    "    for idx, im in enumerate(image_batch):\n",
    "        im = np.squeeze(im, axis=2)\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w] = im\n",
    "    return img\n",
    "\n",
    "losses_across_epochs = {\n",
    "    \"loss\": [],\n",
    "    \"reconstruction_loss\": [],\n",
    "    \"kl_loss\": [],\n",
    "}\n",
    "batch_num = len(train_dataset)\n",
    "for i in range(epochs):\n",
    "    print(\"Epoch %d: \" % i)\n",
    "    for k, v in losses_across_epochs.items():\n",
    "        losses_across_epochs[k].append(0)\n",
    "    for data in train_dataset:\n",
    "        cur_loss = vae.train_step(data)\n",
    "        for k, v in cur_loss.items():\n",
    "            losses_across_epochs[k][-1] += cur_loss[k].numpy() / batch_num\n",
    "        generated_image = vae.sample(data)\n",
    "    print(\"Total loss: %d\" % losses_across_epochs['loss'][-1])\n",
    "    im_merged = merge_images(generated_image.numpy(), [8,8])\n",
    "    plt.imsave('./images/vae_adapted/%d.png' % i, im_merged, cmap='gray')\n",
    "for k, v in losses_across_epochs.items():\n",
    "    np.save('./results/vae_adapted/%s' % k, np.array(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "for i, data in enumerate(test_dataset):\n",
    "    _, _, mask_batch = data\n",
    "    generated_image = vae.sample(data)\n",
    "    reconstruction_loss = tf.reduce_sum(\n",
    "        tf.keras.losses.binary_crossentropy(mask_batch, generated_image), [1,2]\n",
    "    )\n",
    "    test_loss += tf.reduce_mean(reconstruction_loss).numpy()\n",
    "    im_merged = merge_images(generated_image.numpy(), [8,8])\n",
    "    plt.imsave('./images/vae_adapted/test_batch_%d.png' % i, im_merged, cmap='gray')\n",
    "    \n",
    "test_loss = test_loss / len(test_dataset)\n",
    "np.save('./results/vae_adapted/test_loss', np.array([test_loss]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s](2048,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "train_dataset, test_dataset = None, None\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar100.load_data()\n",
    "result = []\n",
    "train_feats = np.load('./data/CIFAR100_%s_train_feat.npy' % model_name)\n",
    "test_feats = np.load('./data/CIFAR100_%s_test_feat.npy' % model_name)\n",
    "\n",
    "for img, img_feat in tqdm(zip(train_images, train_feats)):\n",
    "    img = np.expand_dims(resize(img, (256, 256, 3)), 0)\n",
    "    img_feat = np.expand_dims(img_feat, 0)\n",
    "    depth_feat = tf.random.normal(img_feat.shape)\n",
    "    activation, _, _ = vae.encode(img_feat, depth_feat)\n",
    "    activation = np.squeeze(activation, axis=0)\n",
    "    result.append(activation)\n",
    "\n",
    "np.save('./data/CIFAR100_vae_adapted_%s_encoding_train.npy' % model_name, np.array(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, img_feat in tqdm(zip(test_images, test_feats)):\n",
    "    img = np.expand_dims(resize(img, (256, 256, 3)), 0)\n",
    "    img_feat = np.expand_dims(img_feat, 0)\n",
    "    depth_feat = tf.random.normal(img_feat.shape)\n",
    "    activation, _, _ = vae.encode(img_feat, depth_feat)\n",
    "    activation = np.squeeze(activation, axis=0)\n",
    "    result.append(activation)\n",
    "\n",
    "np.save('./data/CIFAR100_vae_adapted_%s_encoding_test.npy' % model_name, np.array(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}