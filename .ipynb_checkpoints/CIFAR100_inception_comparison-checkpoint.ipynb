{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2048) (10000, 2048)\n",
      "(50000, 2048) (10000, 2048)\n",
      "(50000, 2048) (10000, 2048)\n",
      "(50000, 2048) (10000, 2048)\n"
     ]
    }
   ],
   "source": [
    "model_name = 'inception'\n",
    "\n",
    "cifar100_model_train = np.load(f'./data/CIFAR100_{model_name}_train_feat.npy')\n",
    "cifar100_model_test = np.load(f'./data/CIFAR100_{model_name}_test_feat.npy')\n",
    "print(cifar100_model_train.shape, cifar100_model_test.shape)\n",
    "\n",
    "cifar100_vanilla_train = np.load(f'./data/CIFAR100_vae_vanilla_{model_name}_encoding_train.npy')\n",
    "cifar100_vanilla_test = np.load(f'./data/CIFAR100_vae_vanilla_{model_name}_encoding_test.npy')\n",
    "print(cifar100_vanilla_train.shape, cifar100_vanilla_test.shape)\n",
    "\n",
    "cifar100_injected_train = np.load(f'./data/CIFAR100_vae_injected_{model_name}_encoding_train.npy')\n",
    "cifar100_injected_test = np.load(f'./data/CIFAR100_vae_injected_{model_name}_encoding_test.npy')\n",
    "print(cifar100_injected_train.shape, cifar100_injected_test.shape)\n",
    "\n",
    "cifar100_adapted_train = np.load(f'./data/CIFAR100_vae_adapted_{model_name}_encoding_train.npy')\n",
    "cifar100_adapted_test = np.load(f'./data/CIFAR100_vae_adapted_{model_name}_encoding_test.npy')\n",
    "print(cifar100_adapted_train.shape, cifar100_adapted_test.shape)\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar100.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (cifar100_model_train.shape[1],)\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "val_split=0.2\n",
    "lr = 1e-3\n",
    "callbacks = [\n",
    "    #ReduceLROnPlateau(patience=5, factor=0.1),\n",
    "   # EarlyStopping(patience=10)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = Sequential( [\n",
    "    Input(shape=input_shape),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(100, activation='softmax')\n",
    "], name=model_name)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=lr),  \n",
    "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model_hist = model.fit(\n",
    "    x=cifar100_model_train, \n",
    "    y=train_labels, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs,\n",
    "    validation_split=val_split,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "model_eval = model.evaluate(\n",
    "    x=cifar100_model_test,\n",
    "    y=test_labels,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f'{model.name} test - loss: {model_eval[0]}, accuracy: {model_eval[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vanilla_model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(100, activation='softmax')\n",
    "], name='vanilla')\n",
    "\n",
    "vanilla_model.compile(\n",
    "    optimizer=Adam(lr=lr),\n",
    "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#vanilla_model.summary()\n",
    "\n",
    "vanilla_hist = vanilla_model.fit(\n",
    "    x=cifar100_vanilla_train, \n",
    "    y=train_labels, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs,\n",
    "    validation_split=val_split,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "vanilla_model_eval = vanilla_model.evaluate(\n",
    "    x=cifar100_vanilla_test, \n",
    "    y=test_labels,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f'{vanilla_model.name} test - loss: {vanilla_model_eval[0]}, accuracy: {vanilla_model_eval[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 3s 7ms/step - loss: 5.0933 - accuracy: 0.0103 - val_loss: 4.9537 - val_accuracy: 0.0127\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 4.7604 - accuracy: 0.0212 - val_loss: 4.8813 - val_accuracy: 0.0144\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 4.5399 - accuracy: 0.0368 - val_loss: 4.8276 - val_accuracy: 0.0168\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 4.3610 - accuracy: 0.0486 - val_loss: 4.7909 - val_accuracy: 0.0188\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 4.2009 - accuracy: 0.0717 - val_loss: 4.7687 - val_accuracy: 0.0194\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 4.0637 - accuracy: 0.0948 - val_loss: 4.7556 - val_accuracy: 0.0215\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.9462 - accuracy: 0.1158 - val_loss: 4.7489 - val_accuracy: 0.0233\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.8162 - accuracy: 0.1404 - val_loss: 4.7513 - val_accuracy: 0.0235\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.6909 - accuracy: 0.1729 - val_loss: 4.7640 - val_accuracy: 0.0248\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.5716 - accuracy: 0.1983 - val_loss: 4.7833 - val_accuracy: 0.0249\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.4558 - accuracy: 0.2253 - val_loss: 4.8053 - val_accuracy: 0.0252\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3353 - accuracy: 0.2523 - val_loss: 4.8355 - val_accuracy: 0.0260\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2223 - accuracy: 0.2815 - val_loss: 4.8755 - val_accuracy: 0.0247\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.0996 - accuracy: 0.3070 - val_loss: 4.9173 - val_accuracy: 0.0244\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 2.9853 - accuracy: 0.3336 - val_loss: 4.9700 - val_accuracy: 0.0239\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 2.8589 - accuracy: 0.3631 - val_loss: 5.0242 - val_accuracy: 0.0250\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 2.7403 - accuracy: 0.3923 - val_loss: 5.0814 - val_accuracy: 0.0259\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 5.1027 - accuracy: 0.0304\n",
      "injected test - loss: 5.102689743041992, accuracy: 0.030400000512599945\n",
      "Wall time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "injected_model = tf.keras.Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(100, activation='softmax')\n",
    "], name='injected')\n",
    "\n",
    "injected_model.compile(\n",
    "    optimizer=Adam(lr=lr),\n",
    "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#injected_model.summary()\n",
    "\n",
    "injected_hist = injected_model.fit(\n",
    "    x=cifar100_injected_train, \n",
    "    y=train_labels, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs,\n",
    "    validation_split=val_split,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "injected_model_eval = injected_model.evaluate(\n",
    "    x=cifar100_injected_test, \n",
    "    y=test_labels,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f'{injected_model.name} test - loss: {injected_model_eval[0]}, accuracy: {injected_model_eval[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 4.7748 - accuracy: 0.0205 - val_loss: 4.3846 - val_accuracy: 0.0575\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 3.9300 - accuracy: 0.1303 - val_loss: 4.2256 - val_accuracy: 0.0783\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 3.4301 - accuracy: 0.2236 - val_loss: 4.2762 - val_accuracy: 0.0837\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 3.0489 - accuracy: 0.2890 - val_loss: 4.4543 - val_accuracy: 0.0825\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.7366 - accuracy: 0.3576 - val_loss: 4.6778 - val_accuracy: 0.0798\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.5176 - accuracy: 0.3971 - val_loss: 4.9040 - val_accuracy: 0.0748\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.3181 - accuracy: 0.4370 - val_loss: 5.1651 - val_accuracy: 0.0747\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.1711 - accuracy: 0.4668 - val_loss: 5.3874 - val_accuracy: 0.0754\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 2.0402 - accuracy: 0.4958 - val_loss: 5.6288 - val_accuracy: 0.0699\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.9279 - accuracy: 0.5233 - val_loss: 5.8686 - val_accuracy: 0.0688\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.8433 - accuracy: 0.5359 - val_loss: 6.1146 - val_accuracy: 0.0668\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.7627 - accuracy: 0.5550 - val_loss: 6.3685 - val_accuracy: 0.0653\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6828 - accuracy: 0.5738 - val_loss: 6.5523 - val_accuracy: 0.0648\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6196 - accuracy: 0.5921 - val_loss: 6.8047 - val_accuracy: 0.0638\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5399 - accuracy: 0.6093 - val_loss: 7.0357 - val_accuracy: 0.0605\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.4867 - accuracy: 0.6174 - val_loss: 7.2751 - val_accuracy: 0.0620\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.4395 - accuracy: 0.6308 - val_loss: 7.4732 - val_accuracy: 0.0635\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3887 - accuracy: 0.6407 - val_loss: 7.7526 - val_accuracy: 0.0617\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3413 - accuracy: 0.6533 - val_loss: 7.9468 - val_accuracy: 0.0597\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3045 - accuracy: 0.6608 - val_loss: 8.1711 - val_accuracy: 0.0595\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2548 - accuracy: 0.6705 - val_loss: 8.4193 - val_accuracy: 0.0594\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2387 - accuracy: 0.6751 - val_loss: 8.5877 - val_accuracy: 0.0597\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.2043 - accuracy: 0.6816 - val_loss: 8.8047 - val_accuracy: 0.0575\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1564 - accuracy: 0.6944 - val_loss: 9.0218 - val_accuracy: 0.0588\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.1248 - accuracy: 0.7033 - val_loss: 9.2725 - val_accuracy: 0.0587\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.0984 - accuracy: 0.7072 - val_loss: 9.3899 - val_accuracy: 0.0568\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.0688 - accuracy: 0.7141 - val_loss: 9.7114 - val_accuracy: 0.0546\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.0473 - accuracy: 0.7179 - val_loss: 9.9092 - val_accuracy: 0.0561\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.0314 - accuracy: 0.7224 - val_loss: 10.0684 - val_accuracy: 0.0557\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9975 - accuracy: 0.7327 - val_loss: 10.3136 - val_accuracy: 0.0569\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9704 - accuracy: 0.7377 - val_loss: 10.5102 - val_accuracy: 0.0552\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9519 - accuracy: 0.7382 - val_loss: 10.6973 - val_accuracy: 0.0560\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.9238 - accuracy: 0.7453 - val_loss: 10.9083 - val_accuracy: 0.0552\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9081 - accuracy: 0.7519 - val_loss: 11.0857 - val_accuracy: 0.0557\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.8857 - accuracy: 0.7590 - val_loss: 11.3017 - val_accuracy: 0.0549\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.8600 - accuracy: 0.7644 - val_loss: 11.5649 - val_accuracy: 0.0534\n",
      "Epoch 37/100\n",
      "292/313 [==========================>...] - ETA: 0s - loss: 0.8553 - accuracy: 0.7600"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "adapted_model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    \n",
    "\n",
    "    Dense(100, activation='softmax')\n",
    "],name='adapted' )\n",
    "\n",
    "adapted_model.compile(\n",
    "    optimizer=Adam(lr=lr),             \n",
    "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#adapted_model.summary()\n",
    "\n",
    "adapted_hist = adapted_model.fit(\n",
    "    x=cifar100_adapted_train, \n",
    "    y=train_labels, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs,\n",
    "    validation_split=val_split,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "adapted_model_eval = adapted_model.evaluate(\n",
    "    x=cifar100_adapted_test, \n",
    "    y=test_labels,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f'{adapted_model.name} test - loss: {adapted_model_eval[0]}, accuracy: {adapted_model_eval[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metric = 'accuracy'\n",
    "plt.plot(model_hist.history['loss'], label=f'InceptionNet')\n",
    "plt.plot(vanilla_hist.history['loss'], label='BiModal')\n",
    "plt.plot(injected_hist.history['loss'], label='Injected')\n",
    "plt.plot(adapted_hist.history['loss'], label='Adapted')\n",
    "plt.legend()\n",
    "plt.title(f'{model_name } training Loss')\n",
    "plt.savefig(f'./plots/{model_name}/loss.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model_hist.history[f'{metric}'], label=f'InceptionNet')\n",
    "plt.plot(vanilla_hist.history[f'{metric}'], label='BiModal')\n",
    "plt.plot(injected_hist.history[f'{metric}'], label='Injected')\n",
    "plt.plot(adapted_hist.history[f'{metric}'], label='Adpated')\n",
    "plt.legend()\n",
    "plt.title(f'{model_name} training accuracy')\n",
    "plt.savefig(f'./plots/{model_name}/accuracy.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {\n",
    "    'model': [f'{model_name}', f'{model_name}_vanilla', f'{model_name}_injected', f'{model_name}_adapted'],\n",
    "    f'loss': [model_eval[0], vanilla_model_eval[0], injected_model_eval[0], adapted_model_eval[0]],\n",
    "    f'acc': [model_eval[1], vanilla_model_eval[1], injected_model_eval[1], adapted_model_eval[1]]\n",
    "}\n",
    "\n",
    "test_df = pd.DataFrame(data=test_data)\n",
    "                          \n",
    "test_df.to_csv(f'results/{model_name}_test_df.csv')        \n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.DataFrame(columns=['model', 'loss', 'acc'])\n",
    "\n",
    "for m in ['mobilenet', 'resnet', 'efficientnet', 'inception']:\n",
    "    df = pd.read_csv(f'results/{m}_test_df.csv')\n",
    "    full_df = pd.concat([full_df, df])\n",
    "\n",
    "full_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "full_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "full_df.to_csv(f'results/full_df.csv') \n",
    "\n",
    "full_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
