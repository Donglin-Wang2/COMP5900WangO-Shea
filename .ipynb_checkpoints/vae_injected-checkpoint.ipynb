{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu: 1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import os\n",
    "import tensorflow as tf\n",
    "print(f\"gpu: { len(tf.config.list_physical_devices('GPU')) }\")\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True)\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from vae_injected import VAEInjected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_for_model(model_name, batch_size=64):\n",
    "    assert model_name in ['efficientnet', 'inception','resnet', 'mobilenet']\n",
    "    labels = np.load('./data/LFSD_labels.npy')\n",
    "    depths = np.load('./data/LFSD_depths_repeated.npy')\n",
    "    imgs = np.load('./data/LFSD_imgs.npy')\n",
    "    masks = np.load('./data/LFSD_masks_single.npy')\n",
    "    depths_feat = np.load('./data/LFSD_depths_repeated_%s_feat.npy' % model_name)\n",
    "    imgs_feat = np.load('./data/LFSD_imgs_%s_feat.npy' % model_name)\n",
    "    idx = np.random.permutation(len(labels))\n",
    "    batch_idxs = [idx[i:i + batch_size] for i in range(0, len(labels), batch_size)]\n",
    "    dataset = []\n",
    "    for idx in batch_idxs:\n",
    "        img_batch, depth_batch, mask_batch = imgs[idx], depths[idx], masks[idx]\n",
    "        img_feat_batch, depth_feat_batch = imgs_feat[idx], depths_feat[idx]\n",
    "        dataset.append((img_batch, img_feat_batch, depth_batch, depth_feat_batch, mask_batch))\n",
    "    train_dataset, test_dataset = train_test_split(dataset, test_size=0.3)\n",
    "    print(\"Train dataset contains %d batches of %d samples each\" % (len(train_dataset), batch_size))\n",
    "    print(\"Test dataset contains %d batches of %d samples each\" % (len(test_dataset), batch_size))\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_images(image_batch, size):\n",
    "    h,w = image_batch.shape[1], image_batch.shape[2]\n",
    "    img = np.zeros((int(h*size[0]), w*size[1]))\n",
    "    for idx, im in enumerate(image_batch):\n",
    "        im = np.squeeze(im, axis=2)\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w] = im\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_round(train_dataset, test_dataset, learning_rate, model_name, epochs):\n",
    "    latent_lookup = {\n",
    "        'inception': 2048,\n",
    "        'efficientnet': 1280,\n",
    "        'vgg': 512,\n",
    "        'mobilenet': 1280,\n",
    "        'resnet': 2048,\n",
    "    }\n",
    "    latent_dim = latent_lookup[model_name]\n",
    "    vae = VAEInjected(latent_dim)\n",
    "    vae.compile(optimizer=Adam(learning_rate))\n",
    "    epochs = epochs\n",
    "    # Training Step\n",
    "    losses_across_epochs = {\n",
    "        \"loss\": [],\n",
    "        \"reconstruction_loss\": [],\n",
    "        \"kl_loss\": [],\n",
    "    }\n",
    "    batch_num = len(train_dataset)\n",
    "    for i in range(epochs):\n",
    "       \n",
    "        for k, v in losses_across_epochs.items():\n",
    "            losses_across_epochs[k].append(0)\n",
    "        for data in train_dataset:\n",
    "            cur_loss = vae.train_step(data)\n",
    "            for k, v in cur_loss.items():\n",
    "                losses_across_epochs[k][-1] += cur_loss[k].numpy() / batch_num\n",
    "            generated_image = vae.sample(data)\n",
    "        print(f\"Epoch {i} Total loss: { losses_across_epochs['loss'][-1]}\")\n",
    "        im_merged = merge_images(generated_image.numpy(), [8,8])\n",
    "        plt.imsave('./images/vae_injected/%d.png' % i, im_merged, cmap='gray')\n",
    "    for k, v in losses_across_epochs.items():\n",
    "        np.save('./results/vae_injected/%s_%s' % (model_name, k), np.array(v))\n",
    "    # Testing Step\n",
    "    test_loss = 0\n",
    "    for i, data in enumerate(test_dataset):\n",
    "        _, _, _, _, mask_batch = data\n",
    "        generated_image = vae.sample(data)\n",
    "        reconstruction_loss = tf.reduce_sum(\n",
    "            tf.keras.losses.binary_crossentropy(mask_batch, generated_image), [1,2]\n",
    "        )\n",
    "        test_loss += tf.reduce_mean(reconstruction_loss).numpy()\n",
    "        im_merged = merge_images(generated_image.numpy(), [8,8])\n",
    "        plt.imsave('./images/vae_injected/test_batch_%d.png' % i, im_merged, cmap='gray')\n",
    "        \n",
    "    test_loss = test_loss / len(test_dataset)\n",
    "    np.save('./results/vae_injected/%s_test_loss' % model_name, np.array([test_loss]))\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoding_for_model(vae, model_name):\n",
    "\n",
    "    train_dataset, test_dataset = None, None ## Freeing \n",
    "    (train_images, train_labels), (test_images, test_labels) = datasets.cifar100.load_data()\n",
    "    train_images = train_images / 255.0\n",
    "    test_images = test_images / 255.0\n",
    "    with tf.device('/cpu:0'):\n",
    "        train_images = tf.image.resize(train_images, (256, 256)).numpy()\n",
    "        test_images = tf.image.resize(test_images, (256, 256)).numpy()\n",
    "    train_feats = np.load('./data/CIFAR100_%s_train_feat.npy' % model_name)\n",
    "    test_feats = np.load('./data/CIFAR100_%s_test_feat.npy' % model_name)\n",
    "\n",
    "    train_result, _, _ = vae.encode((train_images[:128], train_feats[:128], None, None, None), rand_depth=True)\n",
    "    for i in tqdm(range(128, len(train_images), 128)):\n",
    "        img = train_images[i:i+128]\n",
    "        img_feat = train_feats[i:i+128]\n",
    "        activation, _, _ = vae.encode((img, img_feat, None, None, None), rand_depth=True)\n",
    "        train_result = tf.concat((train_result, activation), axis=0)\n",
    "    np.save('./data/CIFAR100_vae_injected_%s_encoding_train.npy' % model_name, train_result.numpy())\n",
    "\n",
    "    test_result, _, _ = vae.encode((test_images[:128], test_feats[:128], None, None, None), rand_depth=True)\n",
    "    for i in tqdm(range(128, len(test_images), 128)):\n",
    "        img = test_images[i:i+128]\n",
    "        img_feat = test_feats[i:i+128]\n",
    "        activation, _, _ = vae.encode((img, img_feat, None, None, None), rand_depth=True)\n",
    "        test_result = tf.concat((test_result, activation), axis=0)\n",
    "    np.save('./data/CIFAR100_vae_injected_%s_encoding_test.npy' % model_name, test_result.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset contains 9 batches of 64 samples each\n",
      "Test dataset contains 5 batches of 64 samples each\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-580954fb4bbe>\u001b[0m in \u001b[0;36mtrain_round\u001b[1;34m(train_dataset, test_dataset, learning_rate, model_name, epochs)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mlosses_across_epochs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mcur_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcur_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mlosses_across_epochs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcur_loss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\COMP5900WangO-Shea\\vae_injected.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreconstruction_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mkl_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_loss_tracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1078\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1081\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    585\u001b[0m   \u001b[1;31m# in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m   return [\n\u001b[1;32m--> 587\u001b[1;33m       gen_nn_ops.conv2d_backprop_input(\n\u001b[0m\u001b[0;32m    588\u001b[0m           \u001b[0mshape_0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[1;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1237\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   1240\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Conv2DBackpropInput\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m         \u001b[1;34m\"strides\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"padding\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learning_rate = 1e-4\n",
    "epochs = 100\n",
    "\n",
    "for model_name in ['efficientnet','inception', 'resnet', 'mobilenet', 'vgg']:\n",
    "    train_dataset, test_dataset = load_data_for_model(model_name)\n",
    "    trained_model = train_round(train_dataset, test_dataset, learning_rate, model_name, epochs)\n",
    "    print(\"Gen encoding...\")\n",
    "    get_encoding_for_model(trained_model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
