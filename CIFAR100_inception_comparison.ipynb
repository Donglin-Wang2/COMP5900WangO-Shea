{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2048) (10000, 2048)\n",
      "(50000, 2048) (10000, 2048)\n",
      "(50000, 2048) (10000, 2048)\n",
      "(50000, 2048) (10000, 2048)\n"
     ]
    }
   ],
   "source": [
    "model_name = 'inception'\n",
    "\n",
    "cifar100_model_train = np.load(f'./data/CIFAR100_{model_name}_train_feat.npy')\n",
    "cifar100_model_test = np.load(f'./data/CIFAR100_{model_name}_test_feat.npy')\n",
    "print(cifar100_model_train.shape, cifar100_model_test.shape)\n",
    "\n",
    "cifar100_vanilla_train = np.load(f'./data/CIFAR100_vae_vanilla_{model_name}_encoding_train.npy')\n",
    "cifar100_vanilla_test = np.load(f'./data/CIFAR100_vae_vanilla_{model_name}_encoding_test.npy')\n",
    "print(cifar100_vanilla_train.shape, cifar100_vanilla_test.shape)\n",
    "\n",
    "cifar100_injected_train = np.load(f'./data/CIFAR100_vae_injected_{model_name}_encoding_train.npy')\n",
    "cifar100_injected_test = np.load(f'./data/CIFAR100_vae_injected_{model_name}_encoding_test.npy')\n",
    "print(cifar100_injected_train.shape, cifar100_injected_test.shape)\n",
    "\n",
    "cifar100_adapted_train = np.load(f'./data/CIFAR100_vae_adapted_{model_name}_encoding_train.npy')\n",
    "cifar100_adapted_test = np.load(f'./data/CIFAR100_vae_adapted_{model_name}_encoding_test.npy')\n",
    "print(cifar100_adapted_train.shape, cifar100_adapted_test.shape)\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar100.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (cifar100_model_train.shape[1],)\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "val_split=0.2\n",
    "lr = 1e-3\n",
    "callbacks = [\n",
    "    #ReduceLROnPlateau(patience=5, factor=0.1),\n",
    "   # EarlyStopping(patience=10)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = Sequential( [\n",
    "    Input(shape=input_shape),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(100, activation='softmax')\n",
    "], name=model_name)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(lr=lr),  \n",
    "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "model_hist = model.fit(\n",
    "    x=cifar100_model_train, \n",
    "    y=train_labels, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs,\n",
    "    validation_split=val_split,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "model_eval = model.evaluate(\n",
    "    x=cifar100_model_test,\n",
    "    y=test_labels,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f'{model.name} test - loss: {model_eval[0]}, accuracy: {model_eval[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "vanilla_model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(100, activation='softmax')\n",
    "], name='vanilla')\n",
    "\n",
    "vanilla_model.compile(\n",
    "    optimizer=Adam(lr=lr),\n",
    "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#vanilla_model.summary()\n",
    "\n",
    "vanilla_hist = vanilla_model.fit(\n",
    "    x=cifar100_vanilla_train, \n",
    "    y=train_labels, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs,\n",
    "    validation_split=val_split,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "vanilla_model_eval = vanilla_model.evaluate(\n",
    "    x=cifar100_vanilla_test, \n",
    "    y=test_labels,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f'{vanilla_model.name} test - loss: {vanilla_model_eval[0]}, accuracy: {vanilla_model_eval[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 4.6733 - accuracy: 0.0125 - val_loss: 4.5637 - val_accuracy: 0.0219\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 4.4390 - accuracy: 0.0358 - val_loss: 4.5011 - val_accuracy: 0.0300\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 4.3040 - accuracy: 0.0503 - val_loss: 4.4872 - val_accuracy: 0.0342\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 4.1873 - accuracy: 0.0634 - val_loss: 4.5074 - val_accuracy: 0.0325\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 4.0963 - accuracy: 0.0746 - val_loss: 4.5420 - val_accuracy: 0.0347\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 4.0272 - accuracy: 0.0834 - val_loss: 4.5853 - val_accuracy: 0.0334\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.9601 - accuracy: 0.0906 - val_loss: 4.6283 - val_accuracy: 0.0331\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.9242 - accuracy: 0.0943 - val_loss: 4.6638 - val_accuracy: 0.0316\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.8787 - accuracy: 0.1027 - val_loss: 4.6969 - val_accuracy: 0.0332\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.8549 - accuracy: 0.1057 - val_loss: 4.7405 - val_accuracy: 0.0309\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.8192 - accuracy: 0.1077 - val_loss: 4.7804 - val_accuracy: 0.0316\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.7760 - accuracy: 0.1162 - val_loss: 4.8107 - val_accuracy: 0.0306\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.7678 - accuracy: 0.1216 - val_loss: 4.8319 - val_accuracy: 0.0304\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.7521 - accuracy: 0.1133 - val_loss: 4.8734 - val_accuracy: 0.0310\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.7282 - accuracy: 0.1236 - val_loss: 4.9109 - val_accuracy: 0.0312\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.7085 - accuracy: 0.1230 - val_loss: 4.9205 - val_accuracy: 0.0331\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.6949 - accuracy: 0.1250 - val_loss: 4.9545 - val_accuracy: 0.0310\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.6848 - accuracy: 0.1262 - val_loss: 4.9786 - val_accuracy: 0.0313\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.6795 - accuracy: 0.1254 - val_loss: 5.0069 - val_accuracy: 0.0294\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.6489 - accuracy: 0.1340 - val_loss: 5.0299 - val_accuracy: 0.0311\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.6609 - accuracy: 0.1298 - val_loss: 5.0371 - val_accuracy: 0.0305\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.6361 - accuracy: 0.1339 - val_loss: 5.0475 - val_accuracy: 0.0305\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.6313 - accuracy: 0.1328 - val_loss: 5.0828 - val_accuracy: 0.0307\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.6197 - accuracy: 0.1342 - val_loss: 5.1122 - val_accuracy: 0.0305\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.6138 - accuracy: 0.1340 - val_loss: 5.1168 - val_accuracy: 0.0292\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.5984 - accuracy: 0.1369 - val_loss: 5.1277 - val_accuracy: 0.0291\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.5887 - accuracy: 0.1411 - val_loss: 5.1487 - val_accuracy: 0.0289\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.5763 - accuracy: 0.1408 - val_loss: 5.1604 - val_accuracy: 0.0281\n",
      "Epoch 29/100\n",
      " 39/313 [==>...........................] - ETA: 1s - loss: 3.5554 - accuracy: 0.1448"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "injected_model = tf.keras.Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Dense(16, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(16, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(100, activation='softmax')\n",
    "], name='injected')\n",
    "\n",
    "injected_model.compile(\n",
    "    optimizer=Adam(lr=lr),\n",
    "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#injected_model.summary()\n",
    "\n",
    "injected_hist = injected_model.fit(\n",
    "    x=cifar100_injected_train, \n",
    "    y=train_labels, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs,\n",
    "    validation_split=val_split,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "injected_model_eval = injected_model.evaluate(\n",
    "    x=cifar100_injected_test, \n",
    "    y=test_labels,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f'{injected_model.name} test - loss: {injected_model_eval[0]}, accuracy: {injected_model_eval[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 4.6755 - accuracy: 0.0134 - val_loss: 4.5253 - val_accuracy: 0.0245\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 4.4146 - accuracy: 0.0388 - val_loss: 4.4326 - val_accuracy: 0.0341\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 4.2510 - accuracy: 0.0606 - val_loss: 4.3804 - val_accuracy: 0.0423\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 4.0947 - accuracy: 0.0815 - val_loss: 4.3488 - val_accuracy: 0.0477\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.9774 - accuracy: 0.0918 - val_loss: 4.3661 - val_accuracy: 0.0494\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.8898 - accuracy: 0.1056 - val_loss: 4.3838 - val_accuracy: 0.0505\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.8269 - accuracy: 0.1128 - val_loss: 4.4215 - val_accuracy: 0.0545\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.7672 - accuracy: 0.1185 - val_loss: 4.4737 - val_accuracy: 0.0527\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.7117 - accuracy: 0.1265 - val_loss: 4.5023 - val_accuracy: 0.0518\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.6712 - accuracy: 0.1320 - val_loss: 4.5306 - val_accuracy: 0.0543\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.6318 - accuracy: 0.1400 - val_loss: 4.5539 - val_accuracy: 0.0521\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.6003 - accuracy: 0.1445 - val_loss: 4.5937 - val_accuracy: 0.0528\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.5809 - accuracy: 0.1465 - val_loss: 4.6191 - val_accuracy: 0.0530\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.5677 - accuracy: 0.1423 - val_loss: 4.6711 - val_accuracy: 0.0534\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.5385 - accuracy: 0.1498 - val_loss: 4.6907 - val_accuracy: 0.0540\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.5245 - accuracy: 0.1520 - val_loss: 4.7072 - val_accuracy: 0.0520\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.5038 - accuracy: 0.1554 - val_loss: 4.7220 - val_accuracy: 0.0498\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.4993 - accuracy: 0.1565 - val_loss: 4.7775 - val_accuracy: 0.0487\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.4726 - accuracy: 0.1550 - val_loss: 4.8032 - val_accuracy: 0.0501\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.4692 - accuracy: 0.1603 - val_loss: 4.8131 - val_accuracy: 0.0513\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.4512 - accuracy: 0.1597 - val_loss: 4.8508 - val_accuracy: 0.0501\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.4402 - accuracy: 0.1613 - val_loss: 4.8705 - val_accuracy: 0.0504\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.4256 - accuracy: 0.1653 - val_loss: 4.8917 - val_accuracy: 0.0487\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.4380 - accuracy: 0.1610 - val_loss: 4.9039 - val_accuracy: 0.0492\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.4102 - accuracy: 0.1669 - val_loss: 4.9306 - val_accuracy: 0.0489\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.4112 - accuracy: 0.1676 - val_loss: 4.9390 - val_accuracy: 0.0506\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.4095 - accuracy: 0.1672 - val_loss: 4.9504 - val_accuracy: 0.0498\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3918 - accuracy: 0.1677 - val_loss: 4.9962 - val_accuracy: 0.0506\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.3832 - accuracy: 0.1727 - val_loss: 4.9834 - val_accuracy: 0.0476\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.3795 - accuracy: 0.1697 - val_loss: 5.0253 - val_accuracy: 0.0487\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3850 - accuracy: 0.1698 - val_loss: 5.0106 - val_accuracy: 0.0478\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3640 - accuracy: 0.1765 - val_loss: 5.0237 - val_accuracy: 0.0494\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3668 - accuracy: 0.1735 - val_loss: 5.0581 - val_accuracy: 0.0502\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3627 - accuracy: 0.1718 - val_loss: 5.0681 - val_accuracy: 0.0492\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.3533 - accuracy: 0.1756 - val_loss: 5.0786 - val_accuracy: 0.0479\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.3528 - accuracy: 0.1741 - val_loss: 5.1019 - val_accuracy: 0.0474\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3450 - accuracy: 0.1775 - val_loss: 5.1086 - val_accuracy: 0.0494\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3358 - accuracy: 0.1755 - val_loss: 5.1434 - val_accuracy: 0.0495\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3400 - accuracy: 0.1705 - val_loss: 5.1402 - val_accuracy: 0.0479\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3141 - accuracy: 0.1807 - val_loss: 5.1574 - val_accuracy: 0.0484\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3283 - accuracy: 0.1742 - val_loss: 5.1822 - val_accuracy: 0.0477\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3196 - accuracy: 0.1777 - val_loss: 5.1849 - val_accuracy: 0.0496\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3179 - accuracy: 0.1826 - val_loss: 5.1716 - val_accuracy: 0.0482\n",
      "Epoch 44/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3168 - accuracy: 0.1823 - val_loss: 5.1763 - val_accuracy: 0.0486\n",
      "Epoch 45/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3075 - accuracy: 0.1808 - val_loss: 5.2147 - val_accuracy: 0.0484\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3057 - accuracy: 0.1796 - val_loss: 5.2148 - val_accuracy: 0.0485\n",
      "Epoch 47/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3052 - accuracy: 0.1793 - val_loss: 5.2089 - val_accuracy: 0.0481\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3070 - accuracy: 0.1831 - val_loss: 5.2413 - val_accuracy: 0.0487\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3156 - accuracy: 0.1786 - val_loss: 5.2587 - val_accuracy: 0.0485\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3010 - accuracy: 0.1773 - val_loss: 5.2353 - val_accuracy: 0.0492\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2896 - accuracy: 0.1825 - val_loss: 5.2861 - val_accuracy: 0.0493\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.3016 - accuracy: 0.1811 - val_loss: 5.2829 - val_accuracy: 0.0495\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2838 - accuracy: 0.1849 - val_loss: 5.2829 - val_accuracy: 0.0476\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2831 - accuracy: 0.1807 - val_loss: 5.2838 - val_accuracy: 0.0496\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2844 - accuracy: 0.1852 - val_loss: 5.3199 - val_accuracy: 0.0480\n",
      "Epoch 56/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2843 - accuracy: 0.1805 - val_loss: 5.3201 - val_accuracy: 0.0475\n",
      "Epoch 57/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2809 - accuracy: 0.1840 - val_loss: 5.3408 - val_accuracy: 0.0488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2841 - accuracy: 0.1841 - val_loss: 5.3275 - val_accuracy: 0.0499\n",
      "Epoch 59/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2650 - accuracy: 0.1873 - val_loss: 5.3268 - val_accuracy: 0.0478\n",
      "Epoch 60/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2661 - accuracy: 0.1870 - val_loss: 5.3142 - val_accuracy: 0.0485\n",
      "Epoch 61/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2743 - accuracy: 0.1841 - val_loss: 5.3164 - val_accuracy: 0.0480\n",
      "Epoch 62/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2630 - accuracy: 0.1882 - val_loss: 5.3557 - val_accuracy: 0.0481\n",
      "Epoch 63/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2663 - accuracy: 0.1859 - val_loss: 5.3704 - val_accuracy: 0.0472\n",
      "Epoch 64/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2521 - accuracy: 0.1890 - val_loss: 5.3541 - val_accuracy: 0.0491\n",
      "Epoch 65/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2435 - accuracy: 0.1911 - val_loss: 5.3634 - val_accuracy: 0.0472\n",
      "Epoch 66/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2524 - accuracy: 0.1894 - val_loss: 5.3927 - val_accuracy: 0.0477\n",
      "Epoch 67/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2542 - accuracy: 0.1881 - val_loss: 5.3712 - val_accuracy: 0.0480\n",
      "Epoch 68/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2628 - accuracy: 0.1862 - val_loss: 5.4104 - val_accuracy: 0.0492\n",
      "Epoch 69/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2627 - accuracy: 0.1845 - val_loss: 5.4073 - val_accuracy: 0.0464\n",
      "Epoch 70/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2568 - accuracy: 0.1870 - val_loss: 5.4159 - val_accuracy: 0.0478\n",
      "Epoch 71/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2367 - accuracy: 0.1915 - val_loss: 5.4169 - val_accuracy: 0.0475\n",
      "Epoch 72/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2425 - accuracy: 0.1881 - val_loss: 5.4542 - val_accuracy: 0.0441\n",
      "Epoch 73/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2448 - accuracy: 0.1896 - val_loss: 5.4295 - val_accuracy: 0.0466\n",
      "Epoch 74/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2465 - accuracy: 0.1899 - val_loss: 5.4428 - val_accuracy: 0.0485\n",
      "Epoch 75/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2367 - accuracy: 0.1903 - val_loss: 5.4481 - val_accuracy: 0.0478\n",
      "Epoch 76/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2324 - accuracy: 0.1909 - val_loss: 5.4469 - val_accuracy: 0.0473\n",
      "Epoch 77/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2283 - accuracy: 0.1898 - val_loss: 5.4740 - val_accuracy: 0.0467\n",
      "Epoch 78/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2245 - accuracy: 0.1919 - val_loss: 5.4593 - val_accuracy: 0.0461\n",
      "Epoch 79/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2285 - accuracy: 0.1897 - val_loss: 5.4745 - val_accuracy: 0.0461\n",
      "Epoch 80/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2260 - accuracy: 0.1903 - val_loss: 5.4881 - val_accuracy: 0.0459\n",
      "Epoch 81/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2187 - accuracy: 0.1922 - val_loss: 5.4948 - val_accuracy: 0.0464\n",
      "Epoch 82/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2249 - accuracy: 0.1909 - val_loss: 5.4901 - val_accuracy: 0.0448\n",
      "Epoch 83/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2235 - accuracy: 0.1925 - val_loss: 5.4962 - val_accuracy: 0.0432\n",
      "Epoch 84/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2205 - accuracy: 0.1927 - val_loss: 5.4948 - val_accuracy: 0.0459\n",
      "Epoch 85/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2261 - accuracy: 0.1911 - val_loss: 5.5069 - val_accuracy: 0.0465\n",
      "Epoch 86/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2239 - accuracy: 0.1918 - val_loss: 5.5173 - val_accuracy: 0.0454\n",
      "Epoch 87/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2212 - accuracy: 0.1915 - val_loss: 5.5152 - val_accuracy: 0.0460\n",
      "Epoch 88/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2177 - accuracy: 0.1923 - val_loss: 5.5081 - val_accuracy: 0.0454\n",
      "Epoch 89/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2190 - accuracy: 0.1942 - val_loss: 5.5217 - val_accuracy: 0.0463\n",
      "Epoch 90/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2090 - accuracy: 0.1950 - val_loss: 5.5234 - val_accuracy: 0.0450\n",
      "Epoch 91/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2166 - accuracy: 0.1958 - val_loss: 5.5281 - val_accuracy: 0.0457\n",
      "Epoch 92/100\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 3.2017 - accuracy: 0.1969 - val_loss: 5.5595 - val_accuracy: 0.0455\n",
      "Epoch 93/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2049 - accuracy: 0.1947 - val_loss: 5.5497 - val_accuracy: 0.0455\n",
      "Epoch 94/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2065 - accuracy: 0.1959 - val_loss: 5.5295 - val_accuracy: 0.0449\n",
      "Epoch 95/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2129 - accuracy: 0.1929 - val_loss: 5.5749 - val_accuracy: 0.0445\n",
      "Epoch 96/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2275 - accuracy: 0.1905 - val_loss: 5.5855 - val_accuracy: 0.0440\n",
      "Epoch 97/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2008 - accuracy: 0.1957 - val_loss: 5.5828 - val_accuracy: 0.0453\n",
      "Epoch 98/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2105 - accuracy: 0.1958 - val_loss: 5.5634 - val_accuracy: 0.0453\n",
      "Epoch 99/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2054 - accuracy: 0.1947 - val_loss: 5.5898 - val_accuracy: 0.0433\n",
      "Epoch 100/100\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 3.2154 - accuracy: 0.1931 - val_loss: 5.6086 - val_accuracy: 0.0451\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 5.5573 - accuracy: 0.0422\n",
      "adapted test - loss: 5.557275295257568, accuracy: 0.0421999990940094\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "adapted_model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Dense(16, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(16, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(100, activation='softmax')\n",
    "],name='adapted' )\n",
    "\n",
    "adapted_model.compile(\n",
    "    optimizer=Adam(lr=lr),             \n",
    "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#adapted_model.summary()\n",
    "\n",
    "adapted_hist = adapted_model.fit(\n",
    "    x=cifar100_adapted_train, \n",
    "    y=train_labels, \n",
    "    batch_size=batch_size, \n",
    "    epochs=epochs,\n",
    "    validation_split=val_split,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "adapted_model_eval = adapted_model.evaluate(\n",
    "    x=cifar100_adapted_test, \n",
    "    y=test_labels,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f'{adapted_model.name} test - loss: {adapted_model_eval[0]}, accuracy: {adapted_model_eval[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metric = 'accuracy'\n",
    "plt.plot(model_hist.history['loss'], label=f'InceptionNet')\n",
    "plt.plot(vanilla_hist.history['loss'], label='BiModal')\n",
    "plt.plot(injected_hist.history['loss'], label='Injected')\n",
    "plt.plot(adapted_hist.history['loss'], label='Adapted')\n",
    "plt.legend()\n",
    "plt.title(f'{model_name } training Loss')\n",
    "plt.savefig(f'./plots/{model_name}/loss.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(model_hist.history[f'{metric}'], label=f'InceptionNet')\n",
    "plt.plot(vanilla_hist.history[f'{metric}'], label='BiModal')\n",
    "plt.plot(injected_hist.history[f'{metric}'], label='Injected')\n",
    "plt.plot(adapted_hist.history[f'{metric}'], label='Adpated')\n",
    "plt.legend()\n",
    "plt.title(f'{model_name} training accuracy')\n",
    "plt.savefig(f'./plots/{model_name}/accuracy.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = {\n",
    "    'model': [f'{model_name}', f'{model_name}_vanilla', f'{model_name}_injected', f'{model_name}_adapted'],\n",
    "    f'loss': [model_eval[0], vanilla_model_eval[0], injected_model_eval[0], adapted_model_eval[0]],\n",
    "    f'acc': [model_eval[1], vanilla_model_eval[1], injected_model_eval[1], adapted_model_eval[1]]\n",
    "}\n",
    "\n",
    "test_df = pd.DataFrame(data=test_data)\n",
    "                          \n",
    "test_df.to_csv(f'results/{model_name}_test_df.csv')        \n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.DataFrame(columns=['model', 'loss', 'acc'])\n",
    "\n",
    "for m in ['mobilenet', 'resnet', 'efficientnet', 'inception']:\n",
    "    df = pd.read_csv(f'results/{m}_test_df.csv')\n",
    "    full_df = pd.concat([full_df, df])\n",
    "\n",
    "full_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "full_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "full_df.to_csv(f'results/full_df.csv') \n",
    "\n",
    "full_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
